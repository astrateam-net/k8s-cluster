---
apiVersion: v1
kind: ConfigMap
metadata:
  name: affine-copilot-script
data:
  endpoint.py: |
    from flask import Flask, request, jsonify, Response, stream_with_context
    import json
    from datetime import datetime
    import os
    import openai

    app = Flask(__name__)

    # Settings from environment
    CREATE_LOG = os.getenv('CREATE_LOG', 'false').lower() == 'true'
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
    OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', '')
    OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'google/gemini-2.0-flash-exp')

    # Log setup
    LOG_PATH = "/app/logs"
    os.makedirs(LOG_PATH, exist_ok=True)

    def get_openai_client(base_url=None):
        """Creates an OpenAI client with the specified base URL."""
        if base_url:
            return openai.OpenAI(api_key=OPENAI_API_KEY, base_url=base_url)
        else:
            return openai.OpenAI(api_key=OPENAI_API_KEY)

    def call_ai(messages, model):
        """Calls the AI model using the OpenAI library."""
        try:
            client = get_openai_client(OPENAI_BASE_URL)
            response = client.chat.completions.create(
                model=model,
                messages=messages,
            )
            return response.choices[0].message.content
        except Exception as e:
            raise Exception(f"An unexpected error occurred: {e}")

    def stream_ai(messages, model):
        """Streams the AI model response using the OpenAI library."""
        try:
            client = get_openai_client(OPENAI_BASE_URL)
            stream = client.chat.completions.create(
                model=model,
                messages=messages,
                stream=True,
            )
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    data = {
                        "choices": [
                            {
                                "delta": {"content": chunk.choices[0].delta.content},
                                "index": 0,
                                "finish_reason": chunk.choices[0].finish_reason,
                            }
                        ]
                    }
                    yield f"data: {json.dumps(data)}\n\n"
            yield "data: [DONE]\n\n"
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
            yield "data: [DONE]\n\n"

    @app.route('/chat/completions', methods=['POST'])
    def chat_completions():
        try:
            data = request.json
            messages = data.get("messages", [])
            stream = data.get("stream", False)

            if not messages:
                return jsonify({"error": "No messages provided"}), 400

            if CREATE_LOG:
                try:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    with open(os.path.join(LOG_PATH, "chat_completions.log"), "a") as f:
                        f.write(f"\n=== {timestamp} ===\n")
                        f.write(f"\nModel: {OPENAI_MODEL}\n")
                        f.write(f"\nBaseUrl: {OPENAI_BASE_URL}\n")
                        f.write(f"\nIP: {request.remote_addr}\n")
                        f.write(json.dumps(data, indent=2) + "\n")
                except Exception as e:
                    print(f"Logging failed: {e}")

            if stream:
                return Response(
                    stream_with_context(stream_ai(messages, OPENAI_MODEL)),
                    mimetype='text/event-stream'
                )
            else:
                content = call_ai(messages, OPENAI_MODEL)
                return jsonify({
                    "choices": [{"message": {"role": "assistant", "content": content}}]
                })

        except Exception as e:
            print(f"Error: {e}")
            return jsonify({"error": str(e)}), 500

    @app.route('/', methods=['GET'])
    def health():
        return jsonify({"status": "ok"}), 200

    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=5000, debug=False)

